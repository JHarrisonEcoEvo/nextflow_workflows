#!/usr/bin/env nextflow
//=============================================================================
//                         paired end fastqs to OTU table
//                                  J. Harrison
//  A Nextflow workflow that takes paired-end reads, filters and demultiplexes,
//  clusters, and makes an OTU table. The output
//  of this workflow is an OTU table, a fasta file with consensus OTU sequences
//
//  Usage: nextflow pe_to_otu --in --key --path_out
//  Example: nextflow pe_to_otu --in sample*_R{1,2}.fastq --key samplekey.csv
//   --path_out ./data/
//
//
//  "in" - should be a glob pattern to unzipped paired-end fastq reads (e.g., "*_{1,2}.fastq")
//  "key" -- The demultiplexing key, which should have the following columns
// (in the correct order!): forwardmid, reversemid, locus, samplename, project,
//  wellposition, plate, midplate, substrate, client_name
//  "path_out" - The output path, which can be wherever you want the files output by
//  this workflow to be written.
//
// To see where time is spent use the workflow report feature of nextflow, e.g.:
// nextflow run <pipeline name> -with-report [file name]
//
// To see what commands are run, which is wise to make sure this does what it
// should, use:
//                  nextflow log "name" -f script
// Where name is the name of the run that is auto-assigned by NF
// (i.e., adjective_famousLastname). You can see all runs by typing nextflow log
// this will let you figure out which run to look at in more depth.

//=============================================================================
//                            Input and log.info
//=============================================================================

outputdir = file(params.path_out) //specify the output directory

log.info """\
         PE 2 OTU - N F   P I P E L I N E
         ===================================
         Input fastq file glob: ${params.in}
         Demultiplexing key: $params.key
         Output directory: $outputdir
         """
         .stripIndent()

// Define the channel for fastqs that is used to handle multiple files in parallel
// The fromFilePairs option makes a tuple with the glob pattern the key
// and the two files associated with that pattern the values.
// The flat option means: "When true the matching files are produced as sole
// elements in the emitted tuples". This keeps any oddness from happening during
// parallel processing.

// NEEDS TO HAVE A HIGHER 'BY' SPLIT INTEGER. THIS IS SET FOR TESTING.
fastq_raw = Channel.fromFilePairs('data/*{1,2}_test.fastq', flat:true)
      .splitFastq(by: 100, pe:true, file:true)

fastq_Fpath_forMachineNameOnly = Channel.fromPath(params.in)

key_path = Channel.fromPath(params.key) //specify that the demux key is a file


//=============================================================================
//                            Begin processes
//=============================================================================

process extractMachineName {
  // Extract the name of the sequencing machine from the input files.
  // This name is used during demultiplexing
  input:
    path fastq_file from fastq_Fpath_forMachineNameOnly

  output:
      stdout machine_name

  script:
      """
      head -n 1 $fastq_file | cut -d: -f1 | sed 's/@//'
      """
  }

//======================================================
  process demux {
    // Take fastq(s) as input and demultiplex them using a perl script written
    // by C. Alex Buerkle and Z. Gompert. This script can handle variable
    // length barcodes from 8 to 10 bases long and allows for one base mismatch
    // correction.

    // The parse reports for all iterations of this process should be combined
    // and summarized in the future.

     publishDir "$params.path_out", pattern: "parsereport*", mode: 'copy'

    input:
      set sampleID, file(read1), file(read2)  from fastq_raw
      path key from key_path
      val machine_name from machine_name

    output:
      path 'parsed_*' into demux_out
      path 'parsereport*' into demux_out_diagnostics

    script:
    """
    parse_count.pl $key $read1 $read2 $machine_name
    """
  }

  demux_out
    .collectFile(name: file("${outputdir}demuxTest.txt"))
    .set {
       demux_cat
     }
